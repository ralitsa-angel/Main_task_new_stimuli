setwd("~/Documents/PhD/MAIN_TASKS/Construct_stimuli/Trust_define_data")
library(tidyverse)
library(plotly)
library(ggpubr)
library(stringi)
rm(list=ls())
# First define the working directory (after selecting session>source file location)
wd <- getwd()
# Define participant initials
part = 'GI'
dir.create(paste0(wd, '/', 'stim_', part))
raw_dat <- read.csv(Sys.glob(paste0(part, '*')))
clean_dat <- raw_dat %>%
select(file_name,slider_4.response) %>%
na.omit() %>%
group_by(file_name) %>%
na.omit() %>%
mutate(mean_rat = round(mean(slider_4.response)), sd_rat = round(sd(slider_4.response), 2))
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
# what are the unique mean ratings?
sort(unique(clean_dat$mean_rat))
View(sum_dat)
View(sum_dat)
clean_dat <- raw_dat %>%
select(file_name,slider_4.response) %>%
na.omit() %>%
group_by(file_name) %>%
na.omit() %>%
mutate(mean_rat = round(mean(slider_4.response)), sd_rat = round(sd(slider_4.response), 2))
View(clean_dat)
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
View(sum_dat)
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
View(sum_dat)
# what are the unique mean ratings?
sort(unique(clean_dat$mean_rat))
View(sum_dat)
f_bottom <- sum_dat %>%
ungroup() %>%
top_n(-6, mean_rat) %>%
mutate(cond = 'risk')
View(f_bottom)
View(f_bottom)
View(f_bottom)
# Select the scale of 7 faces to be used
f_bottom <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk')
View(f_bottom)
# Select the scale of 7 faces to be used
f_bottom <- sum_dat %>%
ungroup() %>%
top_n(-6, mean_rat) %>%
mutate(cond = 'risk')
f_middle <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk') %>%
filter(median(mean_rat))
f_middle <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk') %>%
filter(median(mean_rat) == 1)
View(f_middle)
f_middle <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk') %>%
transmute(median(mean_rat))
View(f_middle)
f_middle <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk') %>%
summarise(median(mean_rat))
View(f_middle)
?summarise
# Select the scale of 7 faces to be used
f_bottom <- sum_dat %>%
ungroup() %>%
top_n(-6, mean_rat) %>%
mutate(cond = 'risk')
View(f_bottom)
f_bottom <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk')
View(f_bottom)
View(f_bottom)
View(sum_dat)
# Find the 8th face, which is for the non-social cognition
f_bottom(4)
# Find the 8th face, which is for the non-social cognition
f_bottom(4,)
# Find the 8th face, which is for the non-social cognition
f_bottom[4]
# Find the 8th face, which is for the non-social cognition
meadian(f_bottom$)
# Find the 8th face, which is for the non-social cognition
meadian(f_bottom$mean_rat$)
# Find the 8th face, which is for the non-social cognition
meadian(f_bottom$mean_rat)
# Find the 8th face, which is for the non-social cognition
median(f_bottom$mean_rat)
View(f_bottom)
View(f_middle)
View(f_bottom)
View(clean_dat)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat))
View(non_soc)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
slice(row_number() = 2)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
slice(row_number() == 2)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
View(non_soc)
# Select the scale of 7 faces to be used
soc <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat) %>%
mutate(cond = 'risk')
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
arrange(mean_rat) %>%
mutate(rank = 1:length(mean_rat)) %>%
rename(file = 'file_name') %>%
bind_rows(f_middle) %>%
select(-slider_4.response)
View(final_dat)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
View(final_dat)
# Select the scale of 7 faces to be used
soc <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
View(final_dat)
library(tidyverse)
library(plotly)
library(ggpubr)
library(stringi)
rm(list=ls())
# First define the working directory (after selecting session>source file location)
wd <- getwd()
# Define participant initials and create a folder
part = 'GI'
dir.create(paste0(wd, '/', 'stim_', part))
## 2nd pilot ----------------------------------------------------------------------------------------
# define current person data
raw_dat <- read.csv(Sys.glob(paste0(part, '*')))
# select right columns, remove NAs
# find mean and sd of each face ratings
clean_dat <- raw_dat %>%
select(file_name,slider_4.response) %>%
na.omit() %>%
group_by(file_name) %>%
na.omit() %>%
mutate(mean_rat = round(mean(slider_4.response)), sd_rat = round(sd(slider_4.response), 2))
# Select the face with minimum SD for each rating category
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
# what are the unique mean ratings?
sort(unique(clean_dat$mean_rat))
# Select the scale of 7 faces to be used
soc <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
write.csv(final_dat, paste0(wd, paste0('/stim_', part, '/6_faces.csv')))
library(tidyverse)
library(plotly)
library(ggpubr)
library(stringi)
rm(list=ls())
# First define the working directory (after selecting session>source file location)
wd <- getwd()
# Define participant initials and create a folder
part = 'GI'
dir.create(paste0(wd, '/', 'stim_', part))
## 2nd pilot ----------------------------------------------------------------------------------------
# define current person data
raw_dat <- read.csv(Sys.glob(paste0(part, '*')))
# select right columns, remove NAs
# find mean and sd of each face ratings
clean_dat <- raw_dat %>%
select(file_name,slider_4.response) %>%
na.omit() %>%
group_by(file_name) %>%
na.omit() %>%
mutate(mean_rat = round(mean(slider_4.response)), sd_rat = round(sd(slider_4.response), 2))
# Select the face with minimum SD for each rating category
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
# what are the unique mean ratings?
sort(unique(clean_dat$mean_rat))
# Select the scale of 7 faces to be used
soc <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
write.csv(final_dat, paste0(wd, paste0('/stim_', part, '/6_faces.csv')))
setwd("~/Documents/PhD/MAIN_TASKS/Construct_stimuli/Trust_define_data")
library(tidyverse)
library(plotly)
library(ggpubr)
library(stringi)
rm(list=ls())
wd <- getwd()
# Define participant initials and create a folder
part = 'GI'
dir.create(paste0(wd, '/', 'stim_', part))
raw_dat <- read.csv(Sys.glob(paste0(part, '*')))
clean_dat <- raw_dat %>%
select(file_name,slider_4.response) %>%
na.omit() %>%
group_by(file_name) %>%
na.omit() %>%
mutate(mean_rat = round(mean(slider_4.response)), sd_rat = round(sd(slider_4.response), 2))
# Select the face with minimum SD for each rating category
sum_dat <- clean_dat %>%
arrange(mean_rat) %>%
group_by(mean_rat) %>%
slice(which.min(sd_rat)) # for each mean rating take the one with the smallets SD
# what are the unique mean ratings?
sort(unique(clean_dat$mean_rat))
# Select the scale of 7 faces to be used
soc <- sum_dat %>%
ungroup() %>%
top_n(-7, mean_rat)
# Find the 8th face, for the non-social cognition
non_soc <- clean_dat %>%
filter(mean_rat == median(f_bottom$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
write.csv(final_dat, paste0(wd, paste0('/stim_', part, '/6_faces.csv')))
non_soc <- clean_dat %>%
filter(mean_rat == median(soc$mean_rat)) %>%
arrange(sd_rat) %>%
filter(row_number() == 2)
# combine the above into a single csv
# give them rank 1 to 6 and 99 for neutral
final_dat <- bind_rows(soc, non_soc) %>%
rename(file = 'file_name') %>%
select(-slider_4.response)
write.csv(final_dat, paste0(wd, paste0('/stim_', part, '/6_faces.csv')))
